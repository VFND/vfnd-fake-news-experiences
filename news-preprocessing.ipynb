{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Preprocessing - Load dữ liệu từ các file CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import và các hàm hỗ trợ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Các thư viện hỗ trợ\n",
    "1. ```urlmarker```: Tham khảo tại [Url extraction in python - Ryan Compton](http://ryancompton.net/2015/02/16/url-extraction-in-python/)\n",
    "2. ```token_sylabling```: Tham khảo tại: [core_nlp/tokenization/base_tokenizer.py](https://github.com/deepai-solutions/core_nlp/blob/master/tokenization/base_tokenizer.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, ast, re, sys\n",
    "import csv\n",
    "import unicodedata as ud\n",
    "import random\n",
    "\n",
    "from text_utils import remove_stopwords, token_sylabling\n",
    "from utils import load_file_with_newline\n",
    "import urlmarker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Các đường dẫn đến các file dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thư mục _Data_ chứa các file trích xuất từ dataset ___[VFND](https://github.com/thanhhocse96/vfnd-vietnamese-fake-news-datasets)___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một số file CSV được trích xuất từ ___VFND___:\n",
    "1. [vn_news_226_tlfr.csv](): Tin tức và Facebook post, 2 trường: _text_ (Với các bài báo là Tiêu đề + Nội dung, với Facebook post là nội dung của post đó) và _label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_text_label_226 = 'vn_news_226_tlfr.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Đường dẫn đến các file từ điển"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_path = './Dictionaries'\n",
    "\n",
    "bi_gram_path = os.path.join(dict_path, 'bi_gram.txt')\n",
    "tri_gram_path = os.path.join(dict_path, 'tri_gram.txt')\n",
    "four_gram_path = os.path.join(dict_path, 'four_gram.txt')\n",
    "\n",
    "stopword_path = os.path.join(dict_path, 'Stopwords_vi.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load các từ điển đó lên và chứa vào các Set() dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_dict = load_file_with_newline(bi_gram_path)\n",
    "tri_dict = load_file_with_newline(tri_gram_path)\n",
    "four_dict = load_file_with_newline(four_gram_path)\n",
    "\n",
    "stopwords = load_file_with_newline(stopword_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đưa các từ trong từ điển về dạng chữ thường"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_gram = [x.lower() for x in bi_dict]\n",
    "tri_gram = [x.lower() for x in tri_dict]\n",
    "four_gram = [x.lower() for x in four_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Thuật toán Longest Matching \n",
    "Thuật toán ___Longest Matching___ gộp các syllable token - tiếng - thành các từ được định nghĩa trong bộ từ điển. Input: \n",
    "1. ```token```: List của các syllable sau khi tách ra\n",
    "2. ```bi_gram, tri_gram, four_gram```: Các set() từ điển đã load ở trên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LongestMatching(token, bi_gram, tri_gram, four_gram):\n",
    "    #token_len: Length of syllable list\n",
    "    token_len = len(token)\n",
    "    cur_id = 0\n",
    "    word_list = []\n",
    "    \n",
    "    #done: True when cur_id reach \n",
    "    done = False\n",
    "    \n",
    "    while (cur_id < token_len) and (not done):\n",
    "        cur_word = token[cur_id]\n",
    "        if(cur_id >= token_len - 1):\n",
    "            word_list.append(cur_word)\n",
    "            done = True\n",
    "        else:\n",
    "            next_word = token[cur_id + 1]\n",
    "            bi_word = \" \".join([cur_word.lower(), next_word.lower()])\n",
    "            if(cur_id >= token_len - 2):\n",
    "                if bi_word in bi_gram:\n",
    "                    word_list.append(\"_\".join([cur_word, next_word]))\n",
    "                    cur_id  = cur_id + 2\n",
    "                else: \n",
    "                    word_list.append(cur_word)\n",
    "                    cur_id  = cur_id + 1\n",
    "                        \n",
    "            else: \n",
    "                bi_next_word = token[cur_id + 2]\n",
    "                tri_word = \" \".join([bi_word, bi_next_word.lower()])\n",
    "                if(cur_id >= token_len - 3):\n",
    "                    if tri_word in tri_gram:\n",
    "                        word_list.append(\"_\".join([cur_word, next_word, bi_next_word]))\n",
    "                        cur_id  = cur_id + 3\n",
    "                    elif bi_word in bi_gram:\n",
    "                        word_list.append(\"_\".join([cur_word, next_word]))\n",
    "                        cur_id = cur_id + 2\n",
    "                    else:\n",
    "                        word_list.append(cur_word)\n",
    "                        cur_id = cur_id + 1\n",
    "                else:\n",
    "                    tri_next_word = token[cur_id + 3]\n",
    "                    four_word = \" \".join([tri_word, tri_next_word.lower()])\n",
    "                    if four_word in four_gram:\n",
    "                        word_list.append(\"_\".join([cur_word, next_word, bi_next_word, tri_next_word]))\n",
    "                        cur_id  = cur_id + 4\n",
    "                    elif tri_word in tri_gram:\n",
    "                        word_list.append(\"_\".join([cur_word, next_word, bi_next_word]))\n",
    "                        cur_id  = cur_id + 3\n",
    "                    elif bi_word in bi_gram:\n",
    "                        word_list.append(\"_\".join([cur_word, next_word]))\n",
    "                        cur_id = cur_id + 2\n",
    "                    else:\n",
    "                        word_list.append(cur_word)\n",
    "                        cur_id = cur_id + 1\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Text Preprocessing\n",
    "Input: văn bản tin tức => Output: Văn bản của các cụm từ đã được gom cụm theo bộ từ điển:\n",
    "1. Chuyển đổi text thành các âm tiết bằng hàm: _token_\\__sylabling_ \n",
    "2. Dùng longest matching để chuyển các tiếng thành các từ dựa theo bộ từ điển\n",
    "3. Loại bỏ stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    token_list = token_sylabling(text)\n",
    "    word_list = LongestMatching(token_list, bi_gram, tri_gram, four_gram)\n",
    "    remove_stopword_list = remove_stopwords(word_list, stopwords)\n",
    "    new_text = ' '.join(remove_stopword_list)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load và xử lý các file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load và xử lý ```vn_news_226_tlfr.csv```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ```vn_news_226_tlfr.csv``` vào List các Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "newslist_1 = []\n",
    "\n",
    "with open(os.path.join(data_path, csv_text_label_226), newline='', encoding = 'UTF-8') as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "    newslist_1 = list(reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List các tin tức đã được tiền xử lý theo mục [1.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_news_1 = []\n",
    "for news in newslist_1:\n",
    "    pre_news = dict()\n",
    "    pre_news['text'] = text_preprocessing(news['text'])\n",
    "    pre_news['label'] = news['label']\n",
    "    preprocessed_news_1.append(pre_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Xuất các kết quả tiền xử lý ra file CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_path = './PreprocessingData'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Xuất kết quả tiền xử lý ```vn_news_226_tlfr.csv``` ra ```preproc_vn_news_226_tlfr.csv```\n",
    "Shuffle thứ tự các tin tức trong ```preprocessed_news_1```, tham khảo tại: [Shuffling a list of objects](https://stackoverflow.com/a/976918/5144980)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_id_list = [i for i in range(len(preprocessed_news_1))]\n",
    "random.shuffle(shuffle_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đưa kết quả preprocessing ra file ```preproc_vn_news_226_tlfr.csv```. Tham khảo thêm tại:\n",
    "1. [How do I write a Python dictionary to a csv file? [duplicate]](https://stackoverflow.com/a/10373268/5144980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text', 'label'])\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "keys = preprocessed_news_1[0].keys()\n",
    "print(keys)\n",
    "print(type(preprocessed_news_1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(preproc_path, 'preproc_vn_news_226_tlfr.csv'), 'w') as csv_file:\n",
    "    dict_writer = csv.DictWriter(csv_file, fieldnames = keys)\n",
    "    dict_writer.writeheader()\n",
    "    for i in range(len(preprocessed_news_1)):\n",
    "        dict_writer.writerow(preprocessed_news_1[shuffle_id_list[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thử nghiệm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ngày', '21/11/2018', ',', 'Đây', 'là', 'game', 'GARRY', \"'\", 'S', 'MOD', ':', 'tuyệt', 'vô', 'âm', 'tín', '==>', '=>', 'chơi', 'trên', 'kênh', 'DR.', 'Trực', 'Tiếp', 'Game', 'test', 'word', ':', 'tu', 'nhân', 'tích', 'đức', 'tructiepgame@gmail.com.vn', 'của', 'tôi', '-', 'Dũng', 'CT.', 'tp.', 'HCM', ',', 'TP.', 'HCM', 'Rất', 'mong', 'nhận', 'được', 'sự', 'ủng', 'hộ', 'của', 'ae.', '+', '+', 'Đăng', 'ký', 'theo', 'dõi', 'kênh', 'tại', 'đây', ':', 'https://goo.gl/A7BCZV', '+', '+', 'LINK', 'TẢI', 'APP', 'CUBETV', ':', 'https://www.cubetv.sg', '+', '+', 'THEO', 'DÕI', 'TTG', 'TRÊN', 'CUBETV', ':', 'http://www.cubetv.sg/18947372', '+', '+', 'DONATE', 'ĐỂ', 'TTG', 'MUA', 'ĐƯỢC', 'NHIỀU', 'GAME', 'HƠN', 'TẠI', ':', '-', 'https://playerduo.com/tructiepgame', '-', 'https://streamlabs.com/tructiepgamevn', '+', '+', 'MUA', '/', 'THUÊ', 'GAME', 'BẢN', 'QUYỀN', 'GIÁ', 'RẺ', 'TẠI', ':', 'Website', ':', 'http://divineshop.vn', 'Fanpage', ':', 'https://www.facebook.com/Divine.Shop', '...', '.', ',', 'da', 'che', 'mắt', 'ngựa']\n"
     ]
    }
   ],
   "source": [
    "text = \"ngày 21/11/2018, Đây là game GARRY'S MOD: tuyệt vô âm tín ==> => chơi trên kênh DR.Trực Tiếp Game test word: tu nhân tích đức  tructiepgame@gmail.com.vn của tôi - Dũng CT. tp.HCM, TP.HCM Rất mong nhận được sự ủng hộ của ae. ++ Đăng ký theo dõi kênh tại đây: https://goo.gl/A7BCZV ++ LINK TẢI APP CUBETV: https://www.cubetv.sg ++ THEO DÕI TTG TRÊN CUBETV: http://www.cubetv.sg/18947372 ++ DONATE ĐỂ TTG MUA ĐƯỢC NHIỀU GAME HƠN TẠI: - https://playerduo.com/tructiepgame - https://streamlabs.com/tructiepgamevn ++ MUA/THUÊ GAME BẢN QUYỀN GIÁ RẺ TẠI: Website: http://divineshop.vn Fanpage: https://www.facebook.com/Divine.Shop...., da che mắt ngựa\"\n",
    "token_list = token_sylabling(text)\n",
    "print(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ngày', '21/11/2018', ',', 'Đây', 'là', 'game', 'GARRY', \"'\", 'S', 'MOD', ':', 'tuyệt_vô_âm_tín', '==>', '=>', 'chơi', 'trên', 'kênh', 'DR.', 'Trực_Tiếp', 'Game', 'test', 'word', ':', 'tu_nhân_tích_đức', 'tructiepgame@gmail.com.vn', 'của', 'tôi', '-', 'Dũng', 'CT.', 'tp.', 'HCM', ',', 'TP.', 'HCM', 'Rất', 'mong', 'nhận', 'được', 'sự', 'ủng_hộ', 'của', 'ae.', '+', '+', 'Đăng_ký', 'theo_dõi', 'kênh', 'tại', 'đây', ':', 'https://goo.gl/A7BCZV', '+', '+', 'LINK', 'TẢI', 'APP', 'CUBETV', ':', 'https://www.cubetv.sg', '+', '+', 'THEO_DÕI', 'TTG', 'TRÊN', 'CUBETV', ':', 'http://www.cubetv.sg/18947372', '+', '+', 'DONATE', 'ĐỂ', 'TTG', 'MUA', 'ĐƯỢC', 'NHIỀU', 'GAME', 'HƠN', 'TẠI', ':', '-', 'https://playerduo.com/tructiepgame', '-', 'https://streamlabs.com/tructiepgamevn', '+', '+', 'MUA', '/', 'THUÊ', 'GAME', 'BẢN_QUYỀN', 'GIÁ', 'RẺ', 'TẠI', ':', 'Website', ':', 'http://divineshop.vn', 'Fanpage', ':', 'https://www.facebook.com/Divine.Shop', '...', '.', ',', 'da_che_mắt_ngựa']\n"
     ]
    }
   ],
   "source": [
    "token_list_1 = LongestMatching(token_list, bi_gram, tri_gram, four_gram)\n",
    "print(token_list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngày 21/11/2018 , Đây game GARRY ' S MOD : tuyệt_vô_âm_tín ==> => chơi kênh DR. Trực_Tiếp Game test word : tu_nhân_tích_đức tructiepgame@gmail.com.vn tôi - Dũng CT. tp. HCM , TP. HCM Rất mong nhận ủng_hộ ae. + + Đăng_ký theo_dõi kênh : https://goo.gl/A7BCZV + + LINK TẢI APP CUBETV : https://www.cubetv.sg + + THEO_DÕI TTG TRÊN CUBETV : http://www.cubetv.sg/18947372 + + DONATE ĐỂ TTG MUA ĐƯỢC NHIỀU GAME HƠN TẠI : - https://playerduo.com/tructiepgame - https://streamlabs.com/tructiepgamevn + + MUA / THUÊ GAME BẢN_QUYỀN GIÁ RẺ TẠI : Website : http://divineshop.vn Fanpage : https://www.facebook.com/Divine.Shop ... . , da_che_mắt_ngựa\n"
     ]
    }
   ],
   "source": [
    "preprocessing_text = text_preprocessing(text)\n",
    "print(preprocessing_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
