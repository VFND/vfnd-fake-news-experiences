{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiền xử lý dữ liệu\n",
    "\n",
    "Mục tiêu: chúng ta load được các dữ liệu từ các file JSON, sau đó sẽ loại bỏ:\n",
    "1. Cleaning: Loại bỏ các dấu câu đã được chuyển thành NCR (numeric character reference)\n",
    "2. Tokenizer -> sau đó loại bỏ Stopwords\n",
    "3. \\[Optional\\] Chuyển từ viết tắt thành từ đầy đủ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,json\n",
    "import pandas as pd\n",
    "\n",
    "import unicodedata as uni\n",
    "import sys\n",
    "\n",
    "import html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_json&#95;files_: List chứa các file JSON trong data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_news = \"Data/\"\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_news) if pos_json.endswith('.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['real_1.json', 'fake_1.json']\n"
     ]
    }
   ],
   "source": [
    "print(json_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tạo dataframe bằng [pandas.DataFrame](http://pandas-docs.github.io/pandas-docs-travis/generated/pandas.Series.loc.html) để có thể lưu các thuộc tính load từ các file JSON đã được load ở trên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.DataFrame(columns=['title', 'text', 'authors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dữ liệu từ các file JSON vào list news theo các thuộc tính: _title_, _text_ và _authors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, js in enumerate(json_files):\n",
    "    with open(os.path.join(path_to_news, js), 'r', encoding='utf-8') as json_file:\n",
    "        json_text = json.load(json_file)\n",
    "        \n",
    "        \n",
    "        title = json_text['title']\n",
    "        text = json_text['text']\n",
    "        author = json_text['authors']\n",
    "        \n",
    "        news.loc[index] = [title, text, author]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loại bỏ dấu câu\n",
    "\n",
    "Trong dữ liệu sau khi được crawl về, các ký tự đặc biệt (ví dụ các dấu câu) sẽ được đổi thành dạng [numeric character reference (ncr)](https://en.wikipedia.org/wiki/Numeric_character_reference). Ví dụ như: Trong file _real&#95;1.json_ phần title (ở bên dưới). \n",
    "\n",
    "Chúng ta phải đổi lại dưới dạng Unicode để có thể loại bỏ phần dấu câu. \n",
    "\n",
    "_html.unescape(str)_: đổi các kí tự dạng __ncr__ về định dạng Unicode của chúng\n",
    "\n",
    "Tham khảo [stackoverflow](https://stackoverflow.com/a/17018874/5144980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_str = news.loc[0]['title']\n",
    "\n",
    "title_str = html.unescape(title_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_remove&#95;punc_: hàm dùng để loại bỏ các kí tự đặc biệt như dấu câu trong định dạng Unicode. Tham khảo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                       if uni.category(chr(i)).startswith('P'))\n",
    "\n",
    "def remove_punc(text):\n",
    "    return text.translate(tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ví dụ:__ Title của _real&#95;1.json_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tung tin 'Mr Bean' qua đời để phát tán virus độc hại\n"
     ]
    }
   ],
   "source": [
    "print(title_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title của _real&#95;1.json_ sau khi loại bỏ kí tự đặc biệt: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tung tin Mr Bean qua đời để phát tán virus độc hại\n"
     ]
    }
   ],
   "source": [
    "new_string = remove_punc(title_str)\n",
    "print(new_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "Bắt đầu xử lý các dữ liệu trong list các file JSON và lưu trong list ___preproc&#95;news___:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hôm 197 nhiều độc giả cảnh báo nhau trên mạng về một loại virus máy tính phát tán qua tin giả Mr Bean  Rowan Atkinson qua đời mạo danh Fox News\n",
      "\n",
      "Thông tin lan truyền cách đây ít phút trên mạng xã hội Theo trang SDE các đối tượng phát tán những bài đăng giả trên mạng xã hội với hình thức như một đường link tin tức tiêu đề là Tin nóng của Fox News Mr Bean Rowan Atkinson vừa qua đời ở tuổi 62 sau một vụ đâm xe trong lúc đóng cảnh hành động mạo hiểm Hôm nay tháng 72017\n",
      "Tung tin Mr Bean qua doi de phat tan virus doc hai hinh anh 1\n",
      "Tin cải chính về cái chết của Rowan Atkinson được đưa ra kịp thời để bảo vệ người dùng khỏi virus Ảnh Chronicle Live \n",
      "\n",
      "Vì gắn với một cơ quan truyền thông lớn là Fox News nên mẩu tin dễ dàng thu hút sự chú ý và tin cậy của độc giả dù thông tin ngày tháng bị sai lệch Trang SDE cảnh báo bất cứ độc giả nào nhìn thấy đường link chứa thông tin này không được bấm vào vì thực chất đó là một virus đội lốt\n",
      "\n",
      "Đường link sẽ dẫn thẳng đến một trang web lừa đảo và mã độc nhảy vào máy tính của người truy cập\n",
      "\n",
      "Đây không phải lần đầu tiên Rowan Atkinson trở thành nạn nhân của tin đồn qua đời Trước đây vào năm 2016 và tháng 3 năm nay từng có một loạt bài thất thiệt khẳng định tài tử Johnny English đã tử vong trong một tai nạn xe ở Los Angeles\n",
      "\n",
      "Thông tin về các ngôi sao qua đời cũng thường xuyên được làm giả để lan truyền virus độc hại Trang web Hoax Slayer đã thống kê hầu hết trường hợp tương tự để cảnh báo độc giả\n",
      "Tung tin Mr Bean qua doi de phat tan virus doc hai hinh anh 2\n",
      "Rất nhiều người nổi tiếng bị kẻ gian tung tin qua đời vì mục đích xấu Ảnh CNN\n",
      "\n",
      "Những tin giả này thường dẫn người dùng đến các trang web cảnh báo máy tính đã bị xâm nhập và yêu cầu người dùng gọi đến số điện thoại hỗ trợ Nhưng khi họ gọi đến những kẻ lừa đảo sẽ thu thập thông tin tài khoản ngân hàng của họ với mục đích thanh toán tiền sửa chữa máy tính hoặc tải phần mềm bảo vệ máy\n",
      "\n",
      "Thực chất đó là các phần mềm kiểm soát máy tính và ăn cắp dữ liệu cài mã độc từ xa\n"
     ]
    }
   ],
   "source": [
    "preproc_news = pd.DataFrame(columns=['title', 'text', 'authors'])\n",
    "\n",
    "for index, js in enumerate(json_files):\n",
    "    with open(os.path.join(path_to_news, js), 'r', encoding='utf-8') as json_file:\n",
    "        json_text = json.load(json_file)\n",
    "        \n",
    "        \n",
    "        title = remove_punc(html.unescape(json_text['title']))\n",
    "        text = remove_punc(html.unescape(json_text['text']))\n",
    "        author = json_text['authors']\n",
    "        \n",
    "        preproc_news.loc[index] = [title, text, author]\n",
    "        \n",
    "print(preproc_news.loc[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tokenizer & Loại StopWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trước hết cần biểu diễn token sau đó loại bỏ đi các stopword\n",
    "\n",
    "Dữ liệu từ điển được lấy từ (các file được chứa trong thư mục ./corpus):\n",
    "1. [deepai-solutions/core_nlp](https://github.com/deepai-solutions/core_nlp/tree/master/tokenization): 2 file _bi_\\__gram.txt_ và _tri_\\__gram.txt_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Cách 1: Sử dụng so khớp dài nhất \n",
    "\n",
    "Sử dụng so khớp dài nhất (longest matching) để tách các từ trong  tin tức vừa loại dấu câu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_n_gram(file_path):\n",
    "    with open(file_path, encoding='utf-8') as n_gram:\n",
    "        words = n_gram.read()\n",
    "        words = ast.literal_eval(words)\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = './corpus/'\n",
    "bi_gram_path = 'bi_gram.txt'\n",
    "tri_gram_path = 'tri_gram.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_gram = load_n_gram(os.path.join(corpus_path, bi_gram_path))\n",
    "tri_gram = load_n_gram(os.path.join(corpus_path, tri_gram_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22705\n"
     ]
    }
   ],
   "source": [
    "print (len(bi_gram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LongestMatching(text, n_gram):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
